% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/RSA_StratUtt.R
\name{bestInfGainUtterance}
\alias{bestInfGainUtterance}
\title{Best information gain utterances}
\usage{
bestInfGainUtterance(
  preferencesPrior,
  validUtterances,
  currentObjects,
  uttToObjProbs,
  objectPreferenceSoftPriors,
  alpha = 1,
  klValueFactor = 1
)
}
\arguments{
\item{preferencesPrior}{A vector of the length the validUtterances vector + 1.

It constructed as such:

\code{preferencesPrior <- rep(1/(length(validUtterances)+1), length(validUtterances)+1).}

The vector contains the probability mass over all feature values present in the scenario plus a "no preference" case.

Gives a prior preferences distribution over the feature values in the scene.}

\item{validUtterances}{A vector of utterances that correspond to all feature values present
in the current objects in the scene.

For example, it only makes sense to utter \emph{"red"} in a scene if there are \emph{red} objects present.}

\item{currentObjects}{A vector of three values in \code{{1,...,27}} specifying the target and the other two objects in the scene.

The target is the first object in the vector \code{(index = 1)}.}

\item{uttToObjProbs}{A matrix.

The rows map each possible utterance that corresponds to each present feature value
of the current objects.
The number of rows of the matrix match the length of the validUtterances vector.

The columns represent the three objects in the scene.

This reflects the obedience-parameter and which objects match the respective utterance.
The matrix shows the probability that a certain object is chosen following a certain utterance,
that is valid in the scene.}

\item{objectPreferenceSoftPriors}{A list of preference priors for all valid utterances based on the object in the scene.

The list has as many rows as the length of the validUtterances vector + 1.

Each row in the list contains a vector of length 3, as there are three objects in the scene.

The extra row is for the case of no preferences whatsoever, i.e. uniform prior over all three objects in the scene.}

\item{alpha}{A parameter between 0 and 1. (Here it's set to = 1)

Exponential scaling of the speaker choosing the utterance that maximizes the chance of the listener getting the target object right.}

\item{klValueFactor}{A parameter that can be negative, 0 or positive (Here it is set to = 1):
\describe{
\item{zero}{Don't care about learning about the feature preferences of the listener}
\item{positive}{Care about learning about the feature preferences of the listener}
\item{negative}{Trying to pick non-ambiguous utterances}
}}
}
\value{
A vector containing the normalized probability over utterances given the listener's object preference priors.

The utterance with the highest probability is the one that maximizes the information gain for the speaker.

The vector has the same length as the validUtterances vector.
}
\description{
Full-RSA

The ultimate function that determines the utterance preferences of a rather
"informed", "pragmatic" speaker considering all possible scenarios.
That is, hypothetically, all utterances are considered. Additionally, the resulting
inferred listener's object preferences are computed assuming the listener
picks a certain object and has certain object preferences.

U(utt | listener's object preference priors) is computed.
The utility is determined as the information gain between prior and posterior of the
determined listener's object preferences.
}
\examples{
\donttest{currentObjects <- c(1,2,3)}
\donttest{allObjects[currentObjects,]}

output:

      shape    pattern color
[1,] "cloud"  "solid" "blue"
[2,] "circle" "solid" "blue"
[3,] "square" "solid" "blue"


\donttest{bestInfGainUtterance(preferencesPrior, validUtterances,

currentObjects,uttToObjProbs, objectPreferenceSoftPriors,

alpha=1, klValueFactor=1)}

output:
[1] 0.0 0.0 0.0 0.5

Since the all the objects present in the scene are solid and blue,
uttering solid or blue, would be optimal to learn something
about the shape preferences of the listener.
This means the speaker would have the best information gain.

}
