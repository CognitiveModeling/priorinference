% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/SRSA_UttChoiceOptimization_iterative.R
\name{getSimpleBestInfGainUttPreferencesIterative}
\alias{getSimpleBestInfGainUttPreferencesIterative}
\title{Get the utterances for the speaker's best information gain
(iterative setting)}
\usage{
getSimpleBestInfGainUttPreferencesIterative(
  preferencesPriorAll,
  currentObjects,
  softPrefValue,
  notObeyInst,
  klValueFactor,
  targetFeature
)
}
\arguments{
\item{preferencesPriorAll}{A vector of length 9.

Probability mass over all feature values.

Gives a prior preferences distribution over all (nine) feature values.}

\item{currentObjects}{A vector of three values in \code{{1,...,27}} specifying the target and the other two objects in the scene.

The target is the first object in the vector \code{(index = 1)}.}

\item{softPrefValue}{A parameter value between \code{[0,infinity)} (The larger the value the higher the tendency towards uniform liking).

Value reflects how categorical the listener's preferences are:

\strong{0:} The listener always picks her preferred object.

If the listener prefers \emph{red} objects, she will always pick the \emph{red} object in the scene.

\strong{infinity:} It is as likely for the listener to pick \emph{green}, \emph{blue} or \emph{red} objects.}

\item{notObeyInst}{Determines the extent to which the instruction of the speaker is obeyed by the listener.

(0 = full obedience, infinity = full instruction ignorance).

\strong{Example:}

\strong{0:} Listener always picks \emph{red} objects following the utterance \emph{"red"}.

\strong{infinity:} Listener as likely to pick \emph{green, blue} or \emph{red} objects even if the utterance is \emph{"red"}.}

\item{klValueFactor}{A parameter that can be negative, zero or positive:
\describe{
\item{zero}{Don't care about learning about feature preferences of the listener}
\item{positive}{Care about learning about feature preferences of the listener}
\item{negative}{Trying to pick non-ambiguous utterances}
}}

\item{targetFeature}{A value between 1 and 3, specifying which feature type- color, shape, or pattern- is considered (for preferences).}
}
\value{
A vector containing the normalized probability over utterances given the listener's object preference priors.

The utterance with the highest probability is the one that maximizes the information gain for the speaker.

posterior preferences over feature values: 3 dimensional array for simulated preferences.

\strong{rows:} utterances, \strong{columns:} preferences, \strong{blocks}: objects.
}
\description{
Simple RSA

Determines the optimal utterance for the best information gain.

These are based on the valid utterances determined from the current objects in the scene.

The inferred listener's object preferences are computed assuming the listener
picks a certain object and has certain object preferences.
}
\details{
This function is only used in X9.

This is the iterative version of \code{\link{getSimpleBestInfGainUttPreferences}}
}
\examples{
\donttest{getSimpleBestInfGainUttPreferencesIterative(preferencesPriorAll, currentObjects, softPrefValue,
notObeyInst, klValueFactor, targetFeature)}

output:
[[1]]
[1] 0.25 0.25 0.25 0.00 0.00 0.25
[[2]]
, , 1

      [,1] [,2]  [,3]    [,4]       [,5]      [,6]       [,7] [,8] [,9]
[1,]    0    0    0    0.3334166   0.33325   0.3333333    0    0    0
[2,]    0    0    0    0.3334166   0.33325   0.3333333    0    0    0
[3,]    0    0    0    0.3334167   0.33325   0.3333333    0    0    0
[4,]    0    0    0    0.0000000   0.00000   0.0000000    0    0    0
[5,]    0    0    0    0.0000000   0.00000   0.0000000    0    0    0
[6,]    0    0    0    0.3334166   0.33325   0.3333333    0    0    0

, , 2

       [,1] [,2] [,3]    [,4]        [,5]      [,6]     [,7] [,8] [,9]
[1,]    0    0    0    0.3334166   0.33325   0.3333333    0    0    0
[2,]    0    0    0    0.3334166   0.33325   0.3333333    0    0    0
[3,]    0    0    0    0.3334167   0.33325   0.3333333    0    0    0
[4,]    0    0    0    0.0000000   0.00000   0.0000000    0    0    0
[5,]    0    0    0    0.0000000   0.00000   0.0000000    0    0    0
[6,]    0    0    0    0.3334166   0.33325   0.3333333    0    0    0

, , 3

       [,1] [,2] [,3]      [,4]      [,5]      [,6]      [,7] [,8] [,9]
[1,]    0    0    0    0.3331667  0.3334999  0.3333333    0    0    0
[2,]    0    0    0    0.3331667  0.3334999  0.3333333    0    0    0
[3,]    0    0    0    0.3331668  0.3334999  0.3333333    0    0    0
[4,]    0    0    0    0.0000000  0.0000000  0.0000000    0    0    0
[5,]    0    0    0    0.0000000  0.0000000  0.0000000    0    0    0
[6,]    0    0    0    0.3331667  0.3334999  0.3333333    0    0    0
}
