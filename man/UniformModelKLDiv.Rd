% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/RSA_StratUttOptimization.R
\name{UniformModelKLDiv}
\alias{UniformModelKLDiv}
\title{Uniform Model Kullback-Leibler divergence determination}
\usage{
UniformModelKLDiv(data)
}
\arguments{
\item{data}{A matrix with data rows.

column structure:

[1:OC1,OC2,OC3,4:UUFeat, 5:Q1Feat,6:Q2Feat]

[7:Q1AnswerV1,V2,V3, 10:Q2AnswerV1,V2,V3]

\strong{1:OC1} Object 1. A value between 1 and 27.

\strong{2:OC2} Object 2. A value between 1 and 27.

\strong{3:OC3} Object 3. A value between 1 and 27.

\strong{4:UUFeat} Uttered feature. A number between 1 and 3. (1: shape, 2: pattern, 3: color)

\strong{5:Q1Feat} Questioned feature 1. A number between 1 and 3. (1: shape, 2: pattern, 3: color).

Example: If you utter "blue" (feature: color), then you can learn something about shape and texture preferences.

\strong{6:Q2Feat} Questioned feature 2. A number between 1 and 3. (1: shape, 2: pattern, 3: color).

Example: If you utter "blue" (feature: color), then you can learn something about shape and texture preferences.

\strong{7:Q1AnswerV1, V2, V3} The columns 7-9 contain the participants' slider values for the first questioned feature.

\strong{10:Q2AnswerV1, V2, C3} The columns 10-12 contain the participants' slider values for the second questioned feature.}
}
\value{
Minimized Kullback-Leibler divergence and the optimal parameters.
}
\description{
Full-RSA

Divergence of the observed distribution from the uniform distribution over preferences.
}
