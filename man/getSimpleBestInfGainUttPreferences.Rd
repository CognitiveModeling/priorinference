% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/SRSA_UttChoiceOptimization.R
\name{getSimpleBestInfGainUttPreferences}
\alias{getSimpleBestInfGainUttPreferences}
\title{Get the utterances for the speaker's best information gain}
\usage{
getSimpleBestInfGainUttPreferences(
  currentObjects,
  softPrefValue,
  notObeyInst,
  klValueFactor
)
}
\arguments{
\item{currentObjects}{A vector of three values in \code{{1,...,27}} specifying the target and the other two objects in the scene.

The target is the first object in the vector \code{(index = 1)}.}

\item{softPrefValue}{A parameter value between \code{[0,infinity)} (The larger the value the higher the tendency towards uniform liking).

Value reflects how categorical the listener's preferences are:

\strong{0:} The listener always picks her preferred object.

If the listener prefers \emph{red} objects, she will always pick the \emph{red} object in the scene.

\strong{infinity:} It is as likely for the listener to pick \emph{green}, \emph{blue} or \emph{red} objects.}

\item{notObeyInst}{Determines the extent to which the instruction of the speaker is obeyed by the listener.

(0 = full obedience, infinity = full instruction ignorance).

\strong{Example:}

\strong{0:} Listener always picks \emph{red} objects following the utterance \emph{"red"}.

\strong{infinity:} Listener as likely to pick \emph{green, blue} or \emph{red} objects even if the utterance is \emph{"red"}.}

\item{klValueFactor}{A parameter that can be negative, zero or positive:
\describe{
\item{zero}{Don't care about learning about feature preferences of the listener}
\item{positive}{Care about learning about feature preferences of the listener}
\item{negative}{Trying to pick non-ambiguous utterances}
}}
}
\value{
A vector containing the normalized probability over utterances given the listener's object preference priors.

The utterance with the highest probability is the one that maximizes the information gain for the speaker.

The vector has the same length as the validUtterances vector.
}
\description{
Simple RSA

Determines the optimal utterance for the best information gain.

These are based on the valid utterances determined from the current objects in the scene.

The inferred listener's object preferences are computed assuming the listener
picks a certain object and has certain object preferences.
}
\details{
This function uses the function \code{\link{simpleBestInfGainUtterance}}.
}
\examples{
In the case of these objects being in a scene:

     [shape] [pattern] [color]
[1,] "cloud"  "solid" "blue"
[2,] "circle" "solid" "blue"
[3,] "square" "solid" "blue"

and these being the indices for the valid utterances:

[1] 1 2 3 4 7 (cloud, circle, square, solid, blue)

Then uttering solid or blue would be best in order to gain
information about the shape preferences of the listener:
\donttest{getSimpleBestInfGainUttPreferences(currentObjects, softPrefValue,
notObeyInst, klValueFactor)}

output:
[1] 0.0 0.0 0.0 0.5 0.5

You can see here that the indices with the highest probability, namely 4 and 5,
correspond to the indices in the validUtterance vector for the feature
values 4 (solid) (index = 4) and 7 (blue) (index = 5).

}
